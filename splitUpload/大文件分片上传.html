<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>大文件分片上传</title>

</head>
<body>
<input type="file" id="uploadFile">
<script src="spark-md5.min.js"></script>
<script>
  const inp = document.getElementById('uploadFile');
  inp.onchange = async (e) => {
    const file = inp.files[0];
    if (!file) return;
    const chunks = createChunks(file, 5 * 1024 * 1024)
    const result = await hash(chunks)
    console.log(result);
  }

  /**
   * 使用递归计算
   * 计算hash值需要读取文件的数据， 使用增量算法一块一块的计算文件的hash
   * @param chunks
   */
  function hash(chunks) {
    return new Promise((resolve, reject) => {
      const spark = new SparkMD5();
      function _read(i) {
        if (i >= chunks.length) {
          resolve(spark.end())
          return
        }
        const blob = chunks[i];
        const reader = new FileReader();
        reader.onload = e => {
          // 读取到字节数组
          const bytes = e.target.result;
          spark.append(bytes);
          _read(i + 1)
        }
        // 读取文件
        reader.readAsArrayBuffer(blob)
      }
      _read(0)
    })
  }

  /**
   * File Blob 只是保存了文件的类型，大小等信息，而不是文件的具体内容
   * 通过hash判断文件的唯一性 使用md5算法计算出hash值
   * @param file
   * @param chunkSize
   * @returns {[]}
   */
  function createChunks(file, chunkSize) {
    const result = [];
    for (let i = 0; i < file.size; i += chunkSize) {
      result.push(file.slice(i, i + chunkSize))
    }
    return result;
  }
</script>
</body>
</html>